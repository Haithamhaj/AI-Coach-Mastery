import streamlit as st
import json
import os
from knowledge_bot import KnowledgeEngine
from icf_data_arabic import COMPETENCIES_AR
from grow_model_data import GROW_MODEL_EN, GROW_MODEL_AR

def show(api_key, language="English"):
    """
    Displays the Learning Hub & AI Tutor.
    """
    # Translations
    t = {
        "English": {
            "title": "ğŸ“š Learning Hub",
            "subtitle": "Master ICF Competencies, Markers, and GROW Model",
            "tab_comp": "Competencies",
            "tab_markers": "PCC Markers",
            "tab_grow": "GROW Model",
            "tab_tutor": "ğŸ¤– AI Tutor",
            "tutor_intro": "Ask me anything about ICF Standards or Coaching Skills!",
            "tutor_placeholder": "e.g., What is the difference between C6 and C7?",
            "chat_history": "Chat History",
            "clear_chat": "Clear Chat",
            "grow_g": "Goal",
            "grow_r": "Reality",
            "grow_o": "Options",
            "grow_w": "Will",
            "grow_desc": "The GROW model is a simple yet powerful framework for structuring coaching sessions.",
            "marker_search": "Search Markers...",
            "comp_select": "Select Competency"
        },
        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
            "title": "ğŸ“š Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø¹Ø±ÙØ©",
            "subtitle": "Ø£ØªÙ‚Ù† Ø¬Ø¯Ø§Ø±Ø§Øª ICFØŒ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§ØªØŒ ÙˆÙ†Ù…ÙˆØ°Ø¬ GROW",
            "tab_comp": "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª",
            "tab_markers": "Ù…Ø¤Ø´Ø±Ø§Øª PCC",
            "tab_grow": "Ù†Ù…ÙˆØ°Ø¬ GROW",
            "tab_tutor": "ğŸ¤– Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ",
            "tutor_intro": "Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø¹Ù† Ù…Ø¹Ø§ÙŠÙŠØ± ICF Ø£Ùˆ Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ÙƒÙˆØªØ´ÙŠÙ†Ø¬!",
            "tutor_placeholder": "Ù…Ø«Ø§Ù„: Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø§Ø±Ø© 6 Ùˆ 7ØŸ",
            "chat_history": "Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
            "clear_chat": "Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
            "grow_g": "Ø§Ù„Ù‡Ø¯Ù (Goal)",
            "grow_r": "Ø§Ù„ÙˆØ§Ù‚Ø¹ (Reality)",
            "grow_o": "Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª (Options)",
            "grow_w": "Ø§Ù„Ø¥Ø±Ø§Ø¯Ø© (Will)",
            "grow_desc": "Ù†Ù…ÙˆØ°Ø¬ GROW Ù‡Ùˆ Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø¨Ø³ÙŠØ· ÙˆÙ‚ÙˆÙŠ Ù„ØªÙ†Ø¸ÙŠÙ… Ø¬Ù„Ø³Ø§Øª Ø§Ù„ÙƒÙˆØªØ´ÙŠÙ†Ø¬.",
            "marker_search": "Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª...",
            "comp_select": "Ø§Ø®ØªØ± Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©"
        }
    }
    
    txt = t[language]
    
    st.title(txt['title'])
    st.caption(txt['subtitle'])
    
    # Initialize Knowledge Engine
    if 'knowledge_engine' not in st.session_state:
        st.session_state.knowledge_engine = KnowledgeEngine(api_key)
        
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        txt['tab_comp'], 
        txt['tab_markers'], 
        txt['tab_grow'], 
        txt['tab_tutor']
    ])
    
    # --- TAB 1: COMPETENCIES ---
    with tab1:
        st.header(txt['tab_comp'])
        
        # Load Competencies
        if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            comps = COMPETENCIES_AR
        else:
            comps = st.session_state.knowledge_engine.context_data.get('competencies', [])
        
        if not comps:
            st.error("Competencies data not found.")
        else:
            for comp in comps:
                with st.expander(f"{comp['id']}. {comp['name']}"):
                    desc_label = "Ø§Ù„ØªØ¹Ø±ÙŠÙ" if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Description"
                    st.markdown(f"**{desc_label}:** {comp['definition']}")
                    
                    # Key Points
                    if 'key_points' in comp:
                        st.markdown("#### ğŸ’¡ Key Points" if language == "English" else "#### ğŸ’¡ Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©")
                        for point in comp['key_points']:
                            st.markdown(f"- {point}")
                            
                    # Common Mistakes
                    if 'common_mistakes' in comp:
                        st.markdown("#### âš ï¸ Common Mistakes" if language == "English" else "#### âš ï¸ Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø©")
                        for mistake in comp['common_mistakes']:
                            st.markdown(f"- {mistake}")
                    
                    # Sub-competencies / Markers (if available in this view)
                    if 'sub_competencies' in comp:
                        st.markdown("#### ğŸ“‹ Detailed Markers" if language == "English" else "#### ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©")
                        for sub in comp['sub_competencies']:
                            st.markdown(f"- **{sub['id']}**: {sub['text']}")
                    elif 'markers' in comp and comp['markers']:
                         st.markdown("#### ğŸ¯ Markers" if language == "English" else "#### ğŸ¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª")
                         for m in comp['markers']:
                             st.markdown(f"- **{m['id']}**: {m['text']}")

    # --- TAB 2: PCC MARKERS ---
    with tab2:
        st.header(txt['tab_markers'])
        
        # Load Markers
        if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            markers_data = COMPETENCIES_AR # Structure matches
        else:
            markers_data = st.session_state.knowledge_engine.context_data.get('markers', [])
        
        if not markers_data:
            st.error("Markers data not found.")
        else:
            # Filter
            comp_names = [c['name'] for c in markers_data]
            selected_comp_name = st.selectbox(txt['comp_select'], ["All"] + comp_names)
            
            search_term = st.text_input(txt['marker_search'])
            
            for comp in markers_data:
                if selected_comp_name != "All" and comp['name'] != selected_comp_name:
                    continue
                
                # Check if any marker matches search
                comp_matches = False
                matching_markers = []
                
                for m in comp.get('markers', []):
                    if search_term.lower() in m['text'].lower() or search_term.lower() in m['id'].lower():
                        comp_matches = True
                        matching_markers.append(m)
                
                if comp_matches or not search_term:
                    st.subheader(f"{comp['id']}: {comp['name']}")
                    markers_to_show = matching_markers if search_term else comp.get('markers', [])
                    
                    for m in markers_to_show:
                        st.info(f"**{m['id']}**: {m['text']}")

    # --- TAB 3: GROW MODEL ---
    with tab3:
        st.header(txt['tab_grow'])
        st.write(txt['grow_desc'])
        
        # Select Data based on Language
        grow_data = GROW_MODEL_AR if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else GROW_MODEL_EN
        
        col1, col2, col3, col4 = st.columns(4)
        
        # Helper to render GROW card
        def render_grow_card(column, phase_key, color_func):
            phase = grow_data[phase_key]
            with column:
                color_func(f"### {phase['name']}")
                st.write(f"**{phase['description']}**")
                st.markdown(f"{phase['details']}")
                
                with st.expander("ğŸ’¡ Tips & Mistakes" if language == "English" else "ğŸ’¡ Ù†ØµØ§Ø¦Ø­ ÙˆØ£Ø®Ø·Ø§Ø¡"):
                    st.markdown("#### ğŸ’¡ Tips" if language == "English" else "#### ğŸ’¡ Ù†ØµØ§Ø¦Ø­")
                    for point in phase['key_points']:
                        st.markdown(f"- {point}")
                        
                    st.markdown("#### âš ï¸ Mistakes" if language == "English" else "#### âš ï¸ Ø£Ø®Ø·Ø§Ø¡")
                    for mistake in phase['common_mistakes']:
                        st.markdown(f"- {mistake}")

                with st.expander("Questions" if language == "English" else "Ø£Ø³Ø¦Ù„Ø© Ù…Ù‚ØªØ±Ø­Ø©"):
                    for q in phase['questions']:
                        st.markdown(f"- {q}")

        render_grow_card(col1, "G", st.success)
        render_grow_card(col2, "R", st.warning)
        render_grow_card(col3, "O", st.info)
        render_grow_card(col4, "W", st.error)

    # --- TAB 4: AI TUTOR ---
    with tab4:
        st.header(txt['tab_tutor'])
        st.info(txt['tutor_intro'])
        
        # Chat History
        if "tutor_messages" not in st.session_state:
            st.session_state.tutor_messages = []
            
        # Display Chat
        for msg in st.session_state.tutor_messages:
            role = msg["role"]
            content = msg["content"]
            with st.chat_message(role):
                st.write(content)
                
        # Chat Input
        if prompt := st.chat_input(txt['tutor_placeholder']):
            # Add user message
            st.session_state.tutor_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
                
            # Generate Answer
            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    response = st.session_state.knowledge_engine.ask_tutor(prompt, language)
                    st.write(response)
                    st.session_state.tutor_messages.append({"role": "assistant", "content": response})
                    
        # Clear Chat
        if st.button(txt['clear_chat']):
            st.session_state.tutor_messages = []
            st.rerun()
