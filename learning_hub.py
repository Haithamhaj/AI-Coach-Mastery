import streamlit as st
import json
import os
from knowledge_bot import KnowledgeEngine
from icf_data_arabic import COMPETENCIES_AR

def show(api_key, language="English"):
    """
    Displays the Learning Hub & AI Tutor.
    """
    # Translations
    t = {
        "English": {
            "title": "ğŸ“š Learning Hub",
            "subtitle": "Master ICF Competencies, Markers, and GROW Model",
            "tab_comp": "Competencies",
            "tab_markers": "PCC Markers",
            "tab_grow": "GROW Model",
            "tab_tutor": "ğŸ¤– AI Tutor",
            "tutor_intro": "Ask me anything about ICF Standards or Coaching Skills!",
            "tutor_placeholder": "e.g., What is the difference between C6 and C7?",
            "chat_history": "Chat History",
            "clear_chat": "Clear Chat",
            "grow_g": "Goal",
            "grow_r": "Reality",
            "grow_o": "Options",
            "grow_w": "Will",
            "grow_desc": "The GROW model is a simple yet powerful framework for structuring coaching sessions.",
            "marker_search": "Search Markers...",
            "comp_select": "Select Competency"
        },
        "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
            "title": "ğŸ“š Ù…Ø±ÙƒØ² Ø§Ù„Ù…Ø¹Ø±ÙØ©",
            "subtitle": "Ø£ØªÙ‚Ù† Ø¬Ø¯Ø§Ø±Ø§Øª ICFØŒ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§ØªØŒ ÙˆÙ†Ù…ÙˆØ°Ø¬ GROW",
            "tab_comp": "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª",
            "tab_markers": "Ù…Ø¤Ø´Ø±Ø§Øª PCC",
            "tab_grow": "Ù†Ù…ÙˆØ°Ø¬ GROW",
            "tab_tutor": "ğŸ¤– Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ",
            "tutor_intro": "Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø¹Ù† Ù…Ø¹Ø§ÙŠÙŠØ± ICF Ø£Ùˆ Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„ÙƒÙˆØªØ´ÙŠÙ†Ø¬!",
            "tutor_placeholder": "Ù…Ø«Ø§Ù„: Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø§Ø±Ø© 6 Ùˆ 7ØŸ",
            "chat_history": "Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
            "clear_chat": "Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©",
            "grow_g": "Ø§Ù„Ù‡Ø¯Ù (Goal)",
            "grow_r": "Ø§Ù„ÙˆØ§Ù‚Ø¹ (Reality)",
            "grow_o": "Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª (Options)",
            "grow_w": "Ø§Ù„Ø¥Ø±Ø§Ø¯Ø© (Will)",
            "grow_desc": "Ù†Ù…ÙˆØ°Ø¬ GROW Ù‡Ùˆ Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø¨Ø³ÙŠØ· ÙˆÙ‚ÙˆÙŠ Ù„ØªÙ†Ø¸ÙŠÙ… Ø¬Ù„Ø³Ø§Øª Ø§Ù„ÙƒÙˆØªØ´ÙŠÙ†Ø¬.",
            "marker_search": "Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª...",
            "comp_select": "Ø§Ø®ØªØ± Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©"
        }
    }
    
    txt = t[language]
    
    st.title(txt['title'])
    st.caption(txt['subtitle'])
    
    # Initialize Knowledge Engine
    if 'knowledge_engine' not in st.session_state:
        st.session_state.knowledge_engine = KnowledgeEngine(api_key)
        
    # Tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        txt['tab_comp'], 
        txt['tab_markers'], 
        txt['tab_grow'], 
        txt['tab_tutor']
    ])
    
    # --- TAB 1: COMPETENCIES ---
    with tab1:
        st.header(txt['tab_comp'])
        
        # Load Competencies
        if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            comps = COMPETENCIES_AR
        else:
            comps = st.session_state.knowledge_engine.context_data.get('competencies', [])
        
        if not comps:
            st.error("Competencies data not found.")
        else:
            for comp in comps:
                with st.expander(f"{comp['id']}. {comp['name']}"):
                    st.markdown(f"**Description:** {comp['definition']}")
                    
                    # Key Points
                    if 'key_points' in comp:
                        st.markdown("#### ğŸ’¡ Key Points" if language == "English" else "#### ğŸ’¡ Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©")
                        for point in comp['key_points']:
                            st.markdown(f"- {point}")
                            
                    # Common Mistakes
                    if 'common_mistakes' in comp:
                        st.markdown("#### âš ï¸ Common Mistakes" if language == "English" else "#### âš ï¸ Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ø¦Ø¹Ø©")
                        for mistake in comp['common_mistakes']:
                            st.markdown(f"- {mistake}")
                    
                    # Sub-competencies / Markers (if available in this view)
                    if 'sub_competencies' in comp:
                        st.markdown("#### ğŸ“‹ Detailed Markers" if language == "English" else "#### ğŸ“‹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©")
                        for sub in comp['sub_competencies']:
                            st.markdown(f"- **{sub['id']}**: {sub['text']}")
                    elif 'markers' in comp and comp['markers']:
                         st.markdown("#### ğŸ¯ Markers" if language == "English" else "#### ğŸ¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª")
                         for m in comp['markers']:
                             st.markdown(f"- **{m['id']}**: {m['text']}")

    # --- TAB 2: PCC MARKERS ---
    with tab2:
        st.header(txt['tab_markers'])
        
        # Load Markers
        if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            markers_data = COMPETENCIES_AR # Structure matches
        else:
            markers_data = st.session_state.knowledge_engine.context_data.get('markers', [])
        
        if not markers_data:
            st.error("Markers data not found.")
        else:
            # Filter
            comp_names = [c['name'] for c in markers_data]
            selected_comp_name = st.selectbox(txt['comp_select'], ["All"] + comp_names)
            
            search_term = st.text_input(txt['marker_search'])
            
            for comp in markers_data:
                if selected_comp_name != "All" and comp['name'] != selected_comp_name:
                    continue
                
                # Check if any marker matches search
                comp_matches = False
                matching_markers = []
                
                for m in comp.get('markers', []):
                    if search_term.lower() in m['text'].lower() or search_term.lower() in m['id'].lower():
                        comp_matches = True
                        matching_markers.append(m)
                
                if comp_matches or not search_term:
                    st.subheader(f"{comp['id']}: {comp['name']}")
                    markers_to_show = matching_markers if search_term else comp.get('markers', [])
                    
                    for m in markers_to_show:
                        st.info(f"**{m['id']}**: {m['text']}")

    # --- TAB 3: GROW MODEL ---
    with tab3:
        st.header(txt['tab_grow'])
        st.write(txt['grow_desc'])
        
        col1, col2, col3, col4 = st.columns(4)
        
        # Translations for GROW descriptions
        grow_desc_g = "ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡Ø¯Ù." if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Defining the objective."
        grow_q_g = "- Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ­Ù‚Ù‚ØŸ\n- Ù…Ø§ Ø£Ù‡Ù…ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±ØŸ" if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "- What do you want to achieve?\n- What is important about this?"
        
        grow_desc_r = "Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ." if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Exploring the current situation."
        grow_q_r = "- Ù…Ø§Ø°Ø§ ÙŠØ­Ø¯Ø« Ø§Ù„Ø¢Ù†ØŸ\n- Ù…Ø§ Ø§Ù„Ø°ÙŠ Ø¬Ø±Ø¨ØªÙ‡ Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†ØŸ" if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "- What is happening now?\n- What have you tried so far?"
        
        grow_desc_o = "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª." if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Generating ideas and strategies."
        grow_q_o = "- Ù…Ø§Ø°Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙØ¹Ù„ØŸ\n- Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª/Ø§Ù„Ø³Ù„Ø¨ÙŠØ§ØªØŸ" if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "- What could you do?\n- What are the pros/cons?"
        
        grow_desc_w = "Ø§Ù„Ø§Ù„ØªØ²Ø§Ù… Ø¨Ø§Ù„Ø¹Ù…Ù„." if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Committing to action."
        grow_q_w = "- Ù…Ø§Ø°Ø§ Ø³ØªÙØ¹Ù„ØŸ\n- Ù…ØªÙ‰ Ø³ØªØ¨Ø¯Ø£ØŸ" if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "- What will you do?\n- When will you start?"

        with col1:
            st.success(f"### {txt['grow_g']}")
            st.write(grow_desc_g)
            with st.expander("Questions" if language == "English" else "Ø£Ø³Ø¦Ù„Ø©"):
                st.markdown(grow_q_g)
                
        with col2:
            st.warning(f"### {txt['grow_r']}")
            st.write(grow_desc_r)
            with st.expander("Questions" if language == "English" else "Ø£Ø³Ø¦Ù„Ø©"):
                st.markdown(grow_q_r)
                
        with col3:
            st.info(f"### {txt['grow_o']}")
            st.write(grow_desc_o)
            with st.expander("Questions" if language == "English" else "Ø£Ø³Ø¦Ù„Ø©"):
                st.markdown(grow_q_o)
                
        with col4:
            st.error(f"### {txt['grow_w']}")
            st.write(grow_desc_w)
            with st.expander("Questions" if language == "English" else "Ø£Ø³Ø¦Ù„Ø©"):
                st.markdown(grow_q_w)

    # --- TAB 4: AI TUTOR ---
    with tab4:
        st.header(txt['tab_tutor'])
        st.info(txt['tutor_intro'])
        
        # Chat History
        if "tutor_messages" not in st.session_state:
            st.session_state.tutor_messages = []
            
        # Display Chat
        for msg in st.session_state.tutor_messages:
            role = msg["role"]
            content = msg["content"]
            with st.chat_message(role):
                st.write(content)
                
        # Chat Input
        if prompt := st.chat_input(txt['tutor_placeholder']):
            # Add user message
            st.session_state.tutor_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.write(prompt)
                
            # Generate Answer
            with st.chat_message("assistant"):
                with st.spinner("Thinking..."):
                    response = st.session_state.knowledge_engine.ask_tutor(prompt, language)
                    st.write(response)
                    st.session_state.tutor_messages.append({"role": "assistant", "content": response})
                    
        # Clear Chat
        if st.button(txt['clear_chat']):
            st.session_state.tutor_messages = []
            st.rerun()
